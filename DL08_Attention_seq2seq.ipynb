{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaehwi-So/DeepLearning_Study/blob/main/DL08_Attention_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('drive/MyDrive/DL2024_201810776/week12')\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "g6tbhDSxqR1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b08a705-149a-4a8f-fe14-39272563b94b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "o_CfMFTvWiwM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 읽고 전처리\n",
        "- 영어와 프랑스어가 매칭되어있는 데이터셋을 사용하였다.\n",
        "- src에 영어, tar에 프랑스어가 매칭되어 있는 구조이다.\n",
        "- https://www.kaggle.com/code/jasoncallaway/fra-txt-details"
      ],
      "metadata": {
        "id": "fHU0x8pXTALr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines = pd.read_csv('dataset/fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
        "del lines['lic']\n",
        "print('전체 샘플의 개수 :',len(lines))"
      ],
      "metadata": {
        "id": "J15UDTQ-UeLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89dfbc94-09ad-4ec4-f817-dacd751b5e4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 개수 : 232736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = lines.loc[:, 'src':'tar']\n",
        "lines = lines[0:30000] # 5만개만 사용\n",
        "lines.sample(10)"
      ],
      "metadata": {
        "id": "nFd6pzRSUjsD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "80afd81a-73a3-4006-cc39-c57735cc5ed1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      src                         tar\n",
              "8566       Is that sweet?    Est-ce que c'est sucré ?\n",
              "9451       This is weird.              C'est bizarre.\n",
              "9418       They're weird.          Ils sont bizarres.\n",
              "924            Be strong.            Sois puissante !\n",
              "17877    Tom is a jockey.          Tom est un jockey.\n",
              "26890  I have a solution.          J'ai une solution.\n",
              "6127        Plug this in.                 Branche ça.\n",
              "8201       I was pleased.          J'ai été contente.\n",
              "16126    I'm a carpenter.          Je suis menuisier.\n",
              "7861       I had no idea.  Je n'en avais aucune idée."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cc4f88c-a1fe-41a2-a946-b35db25acac6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8566</th>\n",
              "      <td>Is that sweet?</td>\n",
              "      <td>Est-ce que c'est sucré ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9451</th>\n",
              "      <td>This is weird.</td>\n",
              "      <td>C'est bizarre.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9418</th>\n",
              "      <td>They're weird.</td>\n",
              "      <td>Ils sont bizarres.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>924</th>\n",
              "      <td>Be strong.</td>\n",
              "      <td>Sois puissante !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17877</th>\n",
              "      <td>Tom is a jockey.</td>\n",
              "      <td>Tom est un jockey.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26890</th>\n",
              "      <td>I have a solution.</td>\n",
              "      <td>J'ai une solution.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6127</th>\n",
              "      <td>Plug this in.</td>\n",
              "      <td>Branche ça.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8201</th>\n",
              "      <td>I was pleased.</td>\n",
              "      <td>J'ai été contente.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16126</th>\n",
              "      <td>I'm a carpenter.</td>\n",
              "      <td>Je suis menuisier.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7861</th>\n",
              "      <td>I had no idea.</td>\n",
              "      <td>Je n'en avais aucune idée.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cc4f88c-a1fe-41a2-a946-b35db25acac6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cc4f88c-a1fe-41a2-a946-b35db25acac6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cc4f88c-a1fe-41a2-a946-b35db25acac6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b9516631-01bc-4880-bce7-d090ab464058\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b9516631-01bc-4880-bce7-d090ab464058')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b9516631-01bc-4880-bce7-d090ab464058 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"lines\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"src\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"I'm a carpenter.\",\n          \"This is weird.\",\n          \"I have a solution.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tar\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Je suis menuisier.\",\n          \"C'est bizarre.\",\n          \"J'ai une solution.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
        "lines.sample(10)"
      ],
      "metadata": {
        "id": "8yqupnZqa2FT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "08175e71-a780-4f1e-9a3f-f4583265abb3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      src                               tar\n",
              "21889   Is this your car?      \\t Est-ce votre voiture ? \\n\n",
              "17306    Take your pills.     \\t Prenez vos médicaments. \\n\n",
              "17724    This is reality.           \\t C'est la réalité. \\n\n",
              "16312    I'm ready to go.     \\t Je suis prêt à y aller. \\n\n",
              "15176    How is it going?            \\t Comment vas-tu ? \\n\n",
              "10495     Buy me a drink.        \\t Offre-moi un verre ! \\n\n",
              "24949   You were tricked.  \\t Vous vous êtes fait avoir. \\n\n",
              "10499     Buy me a drink.        \\t Offrez-moi un coup ! \\n\n",
              "24294   We've got a leak.       \\t Nous avons une fuite. \\n\n",
              "29473  The party is over.          \\t La fête est finie. \\n"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e463d1aa-eb4f-4013-a640-68e910fc5443\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21889</th>\n",
              "      <td>Is this your car?</td>\n",
              "      <td>\\t Est-ce votre voiture ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17306</th>\n",
              "      <td>Take your pills.</td>\n",
              "      <td>\\t Prenez vos médicaments. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17724</th>\n",
              "      <td>This is reality.</td>\n",
              "      <td>\\t C'est la réalité. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16312</th>\n",
              "      <td>I'm ready to go.</td>\n",
              "      <td>\\t Je suis prêt à y aller. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15176</th>\n",
              "      <td>How is it going?</td>\n",
              "      <td>\\t Comment vas-tu ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10495</th>\n",
              "      <td>Buy me a drink.</td>\n",
              "      <td>\\t Offre-moi un verre ! \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24949</th>\n",
              "      <td>You were tricked.</td>\n",
              "      <td>\\t Vous vous êtes fait avoir. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10499</th>\n",
              "      <td>Buy me a drink.</td>\n",
              "      <td>\\t Offrez-moi un coup ! \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24294</th>\n",
              "      <td>We've got a leak.</td>\n",
              "      <td>\\t Nous avons une fuite. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29473</th>\n",
              "      <td>The party is over.</td>\n",
              "      <td>\\t La fête est finie. \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e463d1aa-eb4f-4013-a640-68e910fc5443')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e463d1aa-eb4f-4013-a640-68e910fc5443 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e463d1aa-eb4f-4013-a640-68e910fc5443');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fecd51d9-68fb-41a5-950e-2442c0c10f76\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fecd51d9-68fb-41a5-950e-2442c0c10f76')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fecd51d9-68fb-41a5-950e-2442c0c10f76 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"lines\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"src\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"We've got a leak.\",\n          \"Take your pills.\",\n          \"Buy me a drink.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tar\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\t Nous avons une fuite. \\n\",\n          \"\\t Prenez vos m\\u00e9dicaments. \\n\",\n          \"\\t Offre-moi un verre ! \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  문자 집합 구축하기\n",
        "데이터셋으로부터 문자 단위로 Set을 구축한다"
      ],
      "metadata": {
        "id": "lKGu8Nv2EOq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = set()\n",
        "for line in lines.src: # 1줄씩 읽음\n",
        "    for char in line: # 1개의 문자씩 읽음\n",
        "        src_vocab.add(char)\n",
        "\n",
        "tar_vocab = set()\n",
        "for line in lines.tar:\n",
        "    for char in line:\n",
        "        tar_vocab.add(char)\n",
        "src_vocab_size = len(src_vocab)+1\n",
        "tar_vocab_size = len(tar_vocab)+1\n",
        "print('source 문장의 char 집합 :',src_vocab_size)\n",
        "print('target 문장의 char 집합 :',tar_vocab_size)\n"
      ],
      "metadata": {
        "id": "5r8dD4VvdBq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f871da5-01be-40ba-9ca4-83e550029e79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 char 집합 : 77\n",
            "target 문장의 char 집합 : 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = sorted(list(src_vocab))\n",
        "tar_vocab = sorted(list(tar_vocab))\n",
        "print(src_vocab[45:75])\n",
        "print(tar_vocab[45:75])\n"
      ],
      "metadata": {
        "id": "cG6PXNsAdSxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbebfb0b-85ff-4221-aa8c-ee2a0fc81f11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "print(src_to_index)\n",
        "print(tar_to_index)"
      ],
      "metadata": {
        "id": "P5wl07-RdTuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81edf87e-b821-4e8b-9a1c-997f81c674a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, ',': 10, '-': 11, '.': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, '?': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'E': 29, 'F': 30, 'G': 31, 'H': 32, 'I': 33, 'J': 34, 'K': 35, 'L': 36, 'M': 37, 'N': 38, 'O': 39, 'P': 40, 'Q': 41, 'R': 42, 'S': 43, 'T': 44, 'U': 45, 'V': 46, 'W': 47, 'X': 48, 'Y': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '\\xa0': 76, '«': 77, '»': 78, 'À': 79, 'Ç': 80, 'É': 81, 'Ê': 82, 'Ô': 83, 'à': 84, 'â': 85, 'ç': 86, 'è': 87, 'é': 88, 'ê': 89, 'ë': 90, 'î': 91, 'ï': 92, 'ô': 93, 'ù': 94, 'û': 95, 'œ': 96, '\\u2009': 97, '‘': 98, '’': 99, '\\u202f': 100, '‽': 101}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Character Embedding\n",
        "새로운 단어와 희귀한 단어가 자주 등장하므로 Character Embedding을 택하였고, 문장을 문자 단위로 인코딩해주자."
      ],
      "metadata": {
        "id": "IGtHByPuGXqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = []\n",
        "\n",
        "# 1개의 문장\n",
        "for line in lines.src:\n",
        "  encoded_line = []\n",
        "  # 각 줄에서 1개의 char (Tom came after me)\n",
        "  for char in line:\n",
        "    # 각 char을 정수로 변환 (T, o, m, ,c ...)\n",
        "    encoded_line.append(src_to_index[char])\n",
        "  encoder_input.append(encoded_line)\n",
        "print('원래 source 문장 :', lines.src[:5])\n",
        "print('source 문장의 정수 인코딩 :',encoder_input[:5])\n"
      ],
      "metadata": {
        "id": "fAqWDyRQa2_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c62c22c-d70e-48b5-97b1-01cb63fcec2b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원래 source 문장 : 0    Go.\n",
            "1    Go.\n",
            "2    Go.\n",
            "3    Go.\n",
            "4    Hi.\n",
            "Name: src, dtype: object\n",
            "source 문장의 정수 인코딩 : [[30, 64, 10], [30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input = []\n",
        "for line in lines.tar:\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    encoded_line.append(tar_to_index[char])\n",
        "  decoder_input.append(encoded_line)\n",
        "print('target 문장의 정수 인코딩 :',decoder_input[:5])\n"
      ],
      "metadata": {
        "id": "GGZCll5ibKgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27148208-6a41-4067-c099-bcefb842c7f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장의 정수 인코딩 : [[1, 3, 46, 50, 3, 4, 3, 2], [1, 3, 37, 50, 67, 52, 57, 54, 12, 3, 2], [1, 3, 29, 63, 3, 67, 64, 70, 69, 54, 3, 4, 3, 2], [1, 3, 26, 64, 70, 56, 54, 3, 4, 3, 2], [1, 3, 43, 50, 61, 70, 69, 3, 4, 3, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target = []\n",
        "for line in lines.tar:\n",
        "  timestep = 0\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    if timestep > 0:\n",
        "      encoded_line.append(tar_to_index[char])\n",
        "    timestep = timestep + 1\n",
        "  decoder_target.append(encoded_line)\n",
        "print('target 문장 레이블의 정수 인코딩 :',decoder_target[:5])\n"
      ],
      "metadata": {
        "id": "i2RtS2qYlInJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6771a803-c201-4420-e08a-1574fdab9199"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 문장 레이블의 정수 인코딩 : [[3, 46, 50, 3, 4, 3, 2], [3, 37, 50, 67, 52, 57, 54, 12, 3, 2], [3, 29, 63, 3, 67, 64, 70, 69, 54, 3, 4, 3, 2], [3, 26, 64, 70, 56, 54, 3, 4, 3, 2], [3, 43, 50, 61, 70, 69, 3, 4, 3, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "print('source 문장의 최대 길이 :',max_src_len)\n",
        "print('target 문장의 최대 길이 :',max_tar_len)"
      ],
      "metadata": {
        "id": "NVUR5spDkqcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a062bfc2-1721-4f2e-b3e8-a57f719325c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 최대 길이 : 18\n",
            "target 문장의 최대 길이 : 61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 입력 크기를 통일시키기 위해서 패딩을 추가해준다."
      ],
      "metadata": {
        "id": "DHXnqrQ2HMQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')\n",
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "metadata": {
        "id": "xQPg7Ba3lBAt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 모델 생성"
      ],
      "metadata": {
        "id": "xhLBD607OOjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention layer를 추가한 Seq2Seq 모델 사용하기"
      ],
      "metadata": {
        "id": "ybIq2SyJUk-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Dot, Activation, Lambda, Softmax\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "NLLUpNPeNLlZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-1. Attention Layer 정의"
      ],
      "metadata": {
        "id": "VzfD0xB7ObAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 어텐션 레이어\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "\n",
        "    def call(self, query, key, value):\n",
        "        scores = tf.matmul(query, key, transpose_b=True)\n",
        "        attention_weights = Softmax(axis=-1)(scores)\n",
        "        context_vector = tf.matmul(attention_weights, value)\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "SliYNzs2NOBD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2. Encoder와 Decoder 정의\n",
        "- 기존 seq2seq만 사용했을 때와 달리 Encoder에도 return_sequence를 설정한다."
      ],
      "metadata": {
        "id": "g6DGmTfcOXbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 정의\n",
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "# 디코더 정의\n",
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n"
      ],
      "metadata": {
        "id": "IWbDAxMJNupR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-3. Encoder, Decoder, Attention Layer 조립한 seq2seq 생성\n",
        "- Attention을 추가한 모델에서는 디코더의 각 시점에서 인코더의 출력에 대한 가중치(어텐션 가중치)를 계산하여 사용한다.\n",
        "- Attention 레이어는 디코더의 출력과 인코더의 출력을 입력으로 받아 어텐션 가중치를 계산한다.\n",
        "- Attention을 추가한 모델에서는 어텐션 메커니즘을 통해 계산된 컨텍스트 벡터와 디코더의 출력을 연결(concatenate)하여 디코더의 입력으로 사용"
      ],
      "metadata": {
        "id": "DOvoUa4-PqZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 어텐션 레이어 추가\n",
        "# 1) AttentioLayer  선언\n",
        "attention_layer = AttentionLayer()\n",
        "\n",
        "# 2) context_vector, attention_weights 에 출력 담기\n",
        "context_vector, attention_weights = attention_layer(decoder_outputs, encoder_outputs, encoder_outputs)\n",
        "\n",
        "# 컨텍스트 벡터와 디코더 출력을 연결\n",
        "decoder_concat_input = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "# 출력 레이어\n",
        "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# 전체 모델 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zkdhQz6uNwi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9dee16a-dfa5-4569-9136-9e50e7a232b9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None, 77)]           0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None, 102)]          0         []                            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, None, 256),          342016    ['input_1[0][0]']             \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256)]                                                        \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 256),          367616    ['input_2[0][0]',             \n",
            "                              (None, 256),                           'lstm[0][1]',                \n",
            "                              (None, 256)]                           'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " attention_layer (Attention  ((None, None, 256),          0         ['lstm_1[0][0]',              \n",
            " Layer)                       (None, None, None))                    'lstm[0][0]',                \n",
            "                                                                     'lstm[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, None, 512)            0         ['attention_layer[0][0]',     \n",
            "                                                                     'lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 102)            52326     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 761958 (2.91 MB)\n",
            "Trainable params: 761958 (2.91 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 모델 학습"
      ],
      "metadata": {
        "id": "oR3veEapQI5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "model.fit(\n",
        "    [encoder_input, decoder_input],\n",
        "    decoder_target,\n",
        "    batch_size=64,\n",
        "    epochs=40,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "Bu1uJuRXNz8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31da0757-ffc3-4632-d1ae-ffbdf446ac5e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "375/375 [==============================] - 11s 17ms/step - loss: 1.1066 - accuracy: 0.7147 - val_loss: 0.9820 - val_accuracy: 0.7169\n",
            "Epoch 2/40\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.7415 - accuracy: 0.7846 - val_loss: 0.8149 - val_accuracy: 0.7608\n",
            "Epoch 3/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.6405 - accuracy: 0.8122 - val_loss: 0.7400 - val_accuracy: 0.7799\n",
            "Epoch 4/40\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.5853 - accuracy: 0.8275 - val_loss: 0.6899 - val_accuracy: 0.7937\n",
            "Epoch 5/40\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.5464 - accuracy: 0.8383 - val_loss: 0.6537 - val_accuracy: 0.8052\n",
            "Epoch 6/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.5141 - accuracy: 0.8476 - val_loss: 0.6200 - val_accuracy: 0.8144\n",
            "Epoch 7/40\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4873 - accuracy: 0.8552 - val_loss: 0.5943 - val_accuracy: 0.8229\n",
            "Epoch 8/40\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.4650 - accuracy: 0.8617 - val_loss: 0.5709 - val_accuracy: 0.8296\n",
            "Epoch 9/40\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.4454 - accuracy: 0.8672 - val_loss: 0.5523 - val_accuracy: 0.8348\n",
            "Epoch 10/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4285 - accuracy: 0.8722 - val_loss: 0.5307 - val_accuracy: 0.8416\n",
            "Epoch 11/40\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.4135 - accuracy: 0.8766 - val_loss: 0.5188 - val_accuracy: 0.8449\n",
            "Epoch 12/40\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4003 - accuracy: 0.8805 - val_loss: 0.5139 - val_accuracy: 0.8473\n",
            "Epoch 13/40\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.3880 - accuracy: 0.8843 - val_loss: 0.5014 - val_accuracy: 0.8507\n",
            "Epoch 14/40\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.3769 - accuracy: 0.8875 - val_loss: 0.4889 - val_accuracy: 0.8546\n",
            "Epoch 15/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.3665 - accuracy: 0.8906 - val_loss: 0.4795 - val_accuracy: 0.8575\n",
            "Epoch 16/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.3570 - accuracy: 0.8933 - val_loss: 0.4695 - val_accuracy: 0.8605\n",
            "Epoch 17/40\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.3481 - accuracy: 0.8960 - val_loss: 0.4628 - val_accuracy: 0.8627\n",
            "Epoch 18/40\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.3398 - accuracy: 0.8983 - val_loss: 0.4587 - val_accuracy: 0.8638\n",
            "Epoch 19/40\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.3319 - accuracy: 0.9006 - val_loss: 0.4532 - val_accuracy: 0.8656\n",
            "Epoch 20/40\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.3245 - accuracy: 0.9027 - val_loss: 0.4461 - val_accuracy: 0.8678\n",
            "Epoch 21/40\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.3178 - accuracy: 0.9047 - val_loss: 0.4423 - val_accuracy: 0.8688\n",
            "Epoch 22/40\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.3113 - accuracy: 0.9065 - val_loss: 0.4409 - val_accuracy: 0.8696\n",
            "Epoch 23/40\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.3050 - accuracy: 0.9084 - val_loss: 0.4380 - val_accuracy: 0.8706\n",
            "Epoch 24/40\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.2992 - accuracy: 0.9102 - val_loss: 0.4367 - val_accuracy: 0.8717\n",
            "Epoch 25/40\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.2933 - accuracy: 0.9118 - val_loss: 0.4320 - val_accuracy: 0.8728\n",
            "Epoch 26/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.2879 - accuracy: 0.9133 - val_loss: 0.4288 - val_accuracy: 0.8743\n",
            "Epoch 27/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.2829 - accuracy: 0.9148 - val_loss: 0.4269 - val_accuracy: 0.8744\n",
            "Epoch 28/40\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.2777 - accuracy: 0.9162 - val_loss: 0.4259 - val_accuracy: 0.8756\n",
            "Epoch 29/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.2729 - accuracy: 0.9176 - val_loss: 0.4237 - val_accuracy: 0.8759\n",
            "Epoch 30/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.2684 - accuracy: 0.9189 - val_loss: 0.4251 - val_accuracy: 0.8758\n",
            "Epoch 31/40\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.2635 - accuracy: 0.9203 - val_loss: 0.4251 - val_accuracy: 0.8774\n",
            "Epoch 32/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.2594 - accuracy: 0.9215 - val_loss: 0.4224 - val_accuracy: 0.8773\n",
            "Epoch 33/40\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.2551 - accuracy: 0.9228 - val_loss: 0.4199 - val_accuracy: 0.8782\n",
            "Epoch 34/40\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.2509 - accuracy: 0.9239 - val_loss: 0.4208 - val_accuracy: 0.8792\n",
            "Epoch 35/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.2469 - accuracy: 0.9252 - val_loss: 0.4218 - val_accuracy: 0.8789\n",
            "Epoch 36/40\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.2431 - accuracy: 0.9262 - val_loss: 0.4215 - val_accuracy: 0.8792\n",
            "Epoch 37/40\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.2392 - accuracy: 0.9274 - val_loss: 0.4204 - val_accuracy: 0.8793\n",
            "Epoch 38/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.2356 - accuracy: 0.9284 - val_loss: 0.4221 - val_accuracy: 0.8799\n",
            "Epoch 39/40\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.2320 - accuracy: 0.9293 - val_loss: 0.4195 - val_accuracy: 0.8805\n",
            "Epoch 40/40\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.2284 - accuracy: 0.9306 - val_loss: 0.4210 - val_accuracy: 0.8809\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dcffb9398d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 모델 결과 확인\n",
        "훈련된 모델을 사용해서 입력 시퀀스에 대한 번역을 생성하기 위한 추론 모델을 구성한다.\n",
        "- encoder_model: 인코더 모델을 구성. 인코더의 입력을 주면 Attention value 생성\n",
        "- decoder_model: 디코더 모델을 구성. 디코더의 출력과 인코더의 Attention value를 결합하여 출력"
      ],
      "metadata": {
        "id": "icvNk7xdQmFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 모델\n",
        "encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n",
        "\n",
        "# 디코더\n",
        "# 입력 정의\n",
        "decoder_state_input_h = Input(shape=(256,), name=\"decoder_state_input_h\")\n",
        "decoder_state_input_c = Input(shape=(256,), name=\"decoder_state_input_c\")\n",
        "\n",
        "# 디코더 LSTM\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# 어텐션 레이어 추가\n",
        "context_vector, attention_weights = attention_layer(decoder_outputs, encoder_outputs, encoder_outputs)\n",
        "\n",
        "# 컨텍스트 벡터와 디코더 출력을 결합\n",
        "decoder_concat_input = Concatenate(name=\"concatenate_layer\")([context_vector, decoder_outputs])\n",
        "\n",
        "# 최종 출력 레이어\n",
        "decoder_final_output = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# 디코더 모델 생성\n",
        "decoder_model = Model(\n",
        "    inputs=[decoder_inputs, encoder_outputs, decoder_state_input_h, decoder_state_input_c],\n",
        "    outputs=[decoder_final_output, state_h, state_c, attention_weights]\n",
        ")\n",
        "\n",
        "\n",
        "# 오류 메시지에 나타난 문제를 디버깅하기 위해 모델의 개요를 출력\n",
        "encoder_model.summary()\n",
        "decoder_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "2HOlvfvMU_GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8378a96e-d78a-413b-8e05-5fa3a519dd93"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, 77)]        0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, None, 256),       342016    \n",
            "                              (None, 256),                       \n",
            "                              (None, 256)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 342016 (1.30 MB)\n",
            "Trainable params: 342016 (1.30 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, None, 102)]          0         []                            \n",
            "                                                                                                  \n",
            " decoder_state_input_h (Inp  [(None, 256)]                0         []                            \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " decoder_state_input_c (Inp  [(None, 256)]                0         []                            \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 256),          367616    ['input_2[0][0]',             \n",
            "                              (None, 256),                           'decoder_state_input_h[0][0]'\n",
            "                              (None, 256)]                          , 'decoder_state_input_c[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, None, 256)]          0         []                            \n",
            "                                                                                                  \n",
            " attention_layer (Attention  ((None, None, 256),          0         ['lstm_1[2][0]',              \n",
            " Layer)                       (None, None, None))                    'input_3[0][0]',             \n",
            "                                                                     'input_3[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_layer (Concate  (None, None, 512)            0         ['attention_layer[2][0]',     \n",
            " nate)                                                               'lstm_1[2][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 102)            52326     ['concatenate_layer[1][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 419942 (1.60 MB)\n",
            "Trainable params: 419942 (1.60 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())\n"
      ],
      "metadata": {
        "id": "kPIrjojKUaQO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 번역 생성\n",
        "decode_sequence: 주어진 입력 시퀀스에 대해 번역을 생성하는 함수.\n",
        "- 인코더를 통해 초기 상태를 얻고, 그 상태를 디코더의 초기 상태로 사용하여 디코더를 반복적으로 실행하여 출력을 생성한다."
      ],
      "metadata": {
        "id": "X_ttPG2eQcsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 번역 결과를 디코딩하는 함수\n",
        "def decode_sequence(input_seq):\n",
        "    # 인코더의 상태를 얻음\n",
        "    encoder_output, state_h, state_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # 디코더의 초기 입력 (시작 심볼)\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "    # 디코딩 루프\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c, a = decoder_model.predict([target_seq, encoder_output, state_h, state_c])\n",
        "\n",
        "        # 샘플링\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_tar[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # 종료 조건: 최대 길이 초과 또는 종료 심볼\n",
        "        if (sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 다음 디코더 입력 업데이트\n",
        "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # 상태 업데이트\n",
        "        state_h, state_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "wC1yCZVkVVO2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터 사용 예시\n",
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
        "  input_seq = encoder_input[seq_index:seq_index+1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장:', lines.src[seq_index])\n",
        "  print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "  print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력\n"
      ],
      "metadata": {
        "id": "y5VvDPvnOwSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9babd87-cad4-43b4-c8bc-4970481a52f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 407ms/step\n",
            "1/1 [==============================] - 0s 366ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Go.\n",
            "정답 문장: Bouge ! \n",
            "번역 문장: Va ! \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Hello!\n",
            "정답 문장: Bonjour ! \n",
            "번역 문장: Aidez-vous ! \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Got it!\n",
            "정답 문장: J'ai pigé ! \n",
            "번역 문장: Allez ! \n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Go home.\n",
            "정답 문장: Rentre à la maison. \n",
            "번역 문장: Allez ! \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Forget me.\n",
            "정답 문장: Oublie-moi. \n",
            "번역 문장: Allons-y ransser ! \n"
          ]
        }
      ]
    }
  ]
}